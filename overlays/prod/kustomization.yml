apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - ../../base
  - namespace.yml
  - alb/cluster-role-alb.yml
  - config/configmap-alb.yml
  - alb/cert-manager.yml
  - alb/ingress-controller-alb.yml
  - alb/ingress-class.yml
  - ingress/ingress-alb.yml
#   - autoscaler/service-account.yml
#   - autoscaler/cluster-autoscaler.yml
  - ingress/ingress-argocd.yml
  - autoscaler/service-account.yml
  - autoscaler/cluster-autoscaler.yml

images:
- name: ssssuji/ts-back  # 기존 이미지 이름 -> base 리소스 , 기존 실행되던 이미지이름
  newName: 637423620662.dkr.ecr.ap-northeast-2.amazonaws.com/ts-backend  # 새로운 이미지 이름
  newTag: "95"
- name: ssssuji/ts-front
  newName: 637423620662.dkr.ecr.ap-northeast-2.amazonaws.com/ts-frontend
  newTag: "112"
- name: mo991207/ts-ai
  newName: 637423620662.dkr.ecr.ap-northeast-2.amazonaws.com/ts-ai
  newTag: "52"
helmCharts:
  - name: argo-cd
    releaseName: argocd
    namespace: argocd
    version: 5.29.1 # 원하는 ArgoCD Helm 차트 버전
    repo: https://argoproj.github.io/argo-helm
    valuesInline:
      server:
        service:
          # servicePortHttpName: http
          # servicePortHttp: 80
          # servicePortHttpsName: https
          # servicePortHttps: 443
          type: ClusterIP  # 필요한 경우 NodePort나 LoadBalancer로 변경
          spec:
            clusterIP: None
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                    - key: nodegroup
                      operator: In
                      values:
                        - autoscaler
      controller:
        replicaCount: 1
      configs:
        cm:
          kustomize.buildOptions: "--enable-helm"
        params:
          server:
            basehref: /argo-cd
            rootpath: '/argo-cd'
      controller:
        replicaCount: 1
          spec:
            clusterIP: None
        # ingressGrpc:
        #   enabled: true
        #   isAWSALB: true
        #   awsALB:
        #     backendProtocolVersion: "HTTP2"
        #     serviceType: "ClusterIP"
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                    - key: nodegroup
                      operator: In
                      values:
                        - autoscaler
      controller:
        replicaCount: 1
      configs:
        cm:
          kustomize.buildOptions: "--enable-helm"

  - name: loki-stack
    releaseName: loki-stack
    namespace: monitoring # 원하는 네임스페이스 지정
    version: 2.10.2 # Loki Stack Helm 차트의 버전
    repo: https://grafana.github.io/helm-charts
    valuesInline:
      test_pod:
        enabled: false
      loki:
        # extraEnv:
        #   - name: POD_IP
        #     valueFrom:
        #       fieldRef:
        #         fieldPath: status.podIP
        enabled: true
        persistence:
          enabled: true
          storageClassName: gp2
          accessModes:
            - ReadWriteOnce
          size: 1Gi
        config:
          # memberlist:
          #   join_members:
          #     - loki-stack-memberlist.monitoring.svc.cluster.local
          #   bind_port: 7946
          #   advertise_addr: ${POD_IP}
          schema_config:
            configs:
              - from: "2022-01-01"
                store: boltdb-shipper
                object_store: filesystem
                schema: v11
                index:
                  period: 24h
                  prefix: loki_index_
          storage_config:
            boltdb_shipper:
              active_index_directory: /data/loki/index
              shared_store: filesystem
          table_manager:
            retention_deletes_enabled: true
            retention_period: 168h # 7일
        securityContext:
          fsGroup: 1000
          runAsUser: 1000
          runAsGroup: 1000
      promtail:
        enabled: true # Promtail 활성화
        config:
          clients:
            - url: http://loki-stack.monitoring.svc.cluster.local:3100/loki/api/v1/push
          positions:
            filename: /run/promtail/positions.yaml
          scrape_configs:
            - job_name: kubernetes-pods
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: namespace
                - source_labels: [__meta_kubernetes_pod_name]
                  action: replace
                  target_label: pod
                - source_labels: [__meta_kubernetes_container_name]
                  action: replace
                  target_label: container
      prometheus:
        enabled: true
      grafana:
        enabled: true
        adminPassword: admin123
patches:
  - target:
      kind: Deployment
      name: backend-deployment
      namespace: default
    path: backend/deployment-patch.yml
  - target:
      kind: Deployment
      name: frontend-deployment
      namespace: default
    path: frontend/deployment-patch.yml
  - target:
      kind: Deployment
      name: ai-deployment
      namespace: default
    path: ai/deployment-patch.yml
  - target:
      kind: Service
      name: backend-service
      namespace: default
    path: backend/service-patch.yml
  - target:
      kind: Service
      name: frontend-service
      namespace: default
    path: frontend/service-patch.yml
  - target:
      kind: Service
      name: ai-service
      namespace: default
    path: ai/service-patch.yml
  - target:
      kind: ExternalSecret
      name: ts-config-secrets
      namespace: default
    path: config/external-secret-patch.yml
  - target:
      kind: SecretStore
      name: aws-paramstore
      namespace: default
    path: config/secret-store-patch.yml

  
